{
	"Sample Code for Image Classification": {
		"prefix": "ov:example",
		"body": [
			"import cv2",
			"import numpy as np",
			"from openvino.runtime import Core",
			"",
			"# --------------------------- Step 1. Initialize OpenVINO Runtime Core ------------------------------------------------",
			"ie = Core()",
			"",
			"# --------------------------- Step 2. Read a model --------------------------------------------------------------------",
			"model = ie.read_model(model=${1:'model/v3-small_224_1.0_float.xml'}}",
			"",
			"# --------------------------- Step 3. Loading model to the device -----------------------------------------------------",
			"compiled_model = ie.compile_model(model=model, device_name=${2:'CPU'})",
			"",
			"# --------------------------- Step 4. prepare the input ---------------------------------------------------------------",
			"input_layer = compiled_model.input(0)",
			"output_layer = compiled_model.output(0)",
			"",
			"# The MobileNet network expects images in RGB format",
			"image = cv2.cvtColor(cv2.imread(filename=${3:'data/coco.jpg'}), code=cv2.COLOR_BGR2RGB)",
			"# resize to MobileNet image shape",
			"input_image = cv2.resize(src=image, dsize=(224, 224))",
			"# reshape to network input shape",
			"input_image = np.expand_dims(input_image.transpose(2, 0, 1), 0)",
			"",
			"# --------------------------- Step 5. Do inference ---------------------------------------------------------------",
			"result = compiled_model([input_image])[output_layer]",
			"",
			"# --------------------------- Step 6. Process output ---------------------------------------------------------------",
			"result_index = np.argmax(result)",
			"# Convert the inference result to a class name.",
			"imagenet_classes = open(${4:'utils/imagenet_2012.txt'}).read().splitlines()",
			"# The model description states that for this model, class 0 is background,",
			"# so we add background at the beginning of imagenet_classes",
			"imagenet_classes = ['background'] + imagenet_classes",
			"imagenet_classes[result_index]"
		],
		"description": "Workflow Example"
	},
	"Initialize OpenVINO": {
		"prefix": "ov:init",
		"body": [
			"from openvino.runtime import Core, PartialShape",
			"ie = Core()"
		],
		"description": "Create OpenVINO Runtime Core"
	},
	"Available devices": {
		"prefix": "ov:device",
		"body": [
			"devices = ie.available_devices",
			"for device in devices:",
				"\tdevice_name = ie.get_property(device_name=device, name=\"FULL_DEVICE_NAME\")",
				"\tprint(f\"{device}: {device_name}\")"
		],
		"description": "Show available_devices"
	},
	"Compile the Model": {
		"prefix": "ov:compile",
		"body": [
			"model = ie.read_model(model=\"${1:.xml}\")",
			"compiled_model = ie.compile_model(model=model, device_name=\"${2:CPU}\", config={\"PERFORMANCE_HINT\": \"${3:LATENCY}\"})"
		],
		"description": "Reading and Loading a Model"
	},
	"Set input": {
		"prefix": "ov:input",
		"body": [
			"input_tensor = ov.Tensor(np.ones(shape=(2,8)))",
			"request.set_input_tensor(input_tensor)",
			"request.set_tensor(\"tensor_name\", input_tensor)"
		],
		"description": "Set the input tensor"
	},
	"Process output": {
		"prefix": "ov:output",
		"body": [
			"output_tensor = request.get_output_tensor(0)"
		],
		"description": "Process output tensor"
	},
	"Input Information": {
		"prefix": "ov:inputinfo",
		"body": [
			"model.inputs[0].any_name",
			"input_layer = model.input(0)",
			"print(f\"input precision: {input_layer.element_type}\")",
			"print(f\"input shape: {input_layer.shape}\")"
		],
		"description": "Get model input information"
	},
	"Output Information": {
		"prefix": "ov:outputinfo",
		"body": [
			"model.outputs[0].any_name",
			"output_layer = model.output(0)",
			"print(f\"output precision: {output_layer.element_type}\")",
			"print(f\"output shape: {output_layer.shape}\")"
		],
		"description": "Get model output information"
	},
	"Infer Request": {
		"prefix": "ov:request",
		"body": [
			"request = compiled_model.create_infer_request()"
		],
		"description": "Create an Inference Request"
	},
	"Do inference": {
		"prefix": "ov:infer",
		"body": [
			"request.infer(inputs={model.inputs[0].any_name: input_data})",
			"# request.start_async()",
			"# request.wait()",
			"result = request.get_output_tensor(0).data",
			"# result = compiled_model([input_image])",
			"# output_key = compiled_model.output(model.outputs[0].any_name)",
			"# res = result[output_key][0]"
		],
		"description": "Do inference synchronously"
	},
	"Infer request queue": {
		"prefix": "ov:queue",
		"body": [
			"def callback(infer_request: InferRequest, ${1:i}) -> None:",
				"\treslut = infer_request.get_output_tensor(0).data",
			"# Number of InferRequests that AsyncInferQueue holds",
			"infer_queue = AsyncInferQueue(${2:compiled_model}, ${3:4})",
			"infer_queue.set_callback(callback)",
			"for i in range(len(data)):",
				"\tinfer_queue.start_async({0: data[i], 1: data[i]}, userdata=${1:i})",
			"infer_queue.wait_all()"
		],
		"description": "Create infer request queue and do async inference"
	},
	"Change input shape": {
		"prefix": "ov:reshape",
		"body": [
			"idx_to_shape = dict()",
			"i = 0",
			"for input_obj in model.inputs:",
    			"\tshape = input_obj.get_partial_shape()",
    			"\tidx_to_shape[i] = shape",
    			"\ti += 1",
			"model.reshape(idx_to_shape)"
		],
		"description": "Change input shape"
	},
	"Dynamic shape": {
		"prefix": "ov:dynamic",
		"body": [
			"new_shape = PartialShape(${1:[-1, 3, 544, 544]})",
			"model.reshape({input_layer.any_name: new_shape})"
		],
		"description": "Configure the dynamic input shape"
	},
	"Caching a Model": {
		"prefix": "ov:caching",
		"body": [
			"cache_path = Path(${1:\"model/model_cache\"})",
			"enable_caching = True",
    		"config_dict = {\"CACHE_DIR\": ${2:str(cache_path)}}", 
			"compiled_model = ie.compile_model(model=model, device_name=device_name, config=config_dict)"
		],
		"description": "create a model_cache directory as a subdirectory of model, where the model will be cached for the specified device"
	},
	"Preprocessing API": {
		"prefix": "ov:ppp",
		"body": [
			"ppp = PrePostProcessor(model)",
			"ppp.input().tensor()",
        		"\t.set_spatial_static_shape(h,w)",
        		"\t.set_layout(${1:Layout('NHWC')})", 
			"inputs = model.inputs",
			"ppp.input().model().set_layout(${2:Layout('NCHW')})",
			"ppp.input().preprocess()",
    			"\t.resize(ResizeAlgorithm.RESIZE_LINEAR,224,224)",
    			"\t.mean([0.485, 0.456,0.406])",
    			"\t.scale([0.229, 0.224, 0.225])",
			"ppp.output().tensor().set_element_type(${3:Type.f32})",
			"model = ppp.build()"
		],
		"description": "Integrate Preprocessing steps into execution graph"
	}
}